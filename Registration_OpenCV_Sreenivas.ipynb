{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d25934f",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m im1 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages/monkey_distorted.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)          \u001b[38;5;66;03m# Image that needs to be registered.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m im2 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNoisyGroudTruth.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# trainImage\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m img1 \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2GRAY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m img2 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(im2, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Initiate ORB detector\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "__author__ = \"Sreenivas Bhattiprolu\"\n",
    "__license__ = \"Feel free to copy, I appreciate if you acknowledge Python for Microscopists\"\n",
    "\n",
    "# https://www.youtube.com/watch?v=cA8K8dl-E6k\n",
    "\n",
    "\n",
    "# Brute-Force Matching with ORB Descriptors\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "im1 = cv2.imread('images/monkey_distorted.jpg')          # Image that needs to be registered.\n",
    "im2 = cv2.imread('NoisyGroudTruth.jpg') # trainImage\n",
    "\n",
    "img1 = cv2.cvtColor(im1, cv2.COLOR_BGR2GRAY)\n",
    "img2 = cv2.cvtColor(im2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Initiate ORB detector\n",
    "orb = cv2.ORB_create(50)  #Registration works with at least 50 points\n",
    "\n",
    "# find the keypoints and descriptors with orb\n",
    "kp1, des1 = orb.detectAndCompute(img1, None)  #kp1 --> list of keypoints\n",
    "kp2, des2 = orb.detectAndCompute(img2, None)\n",
    "\n",
    "#Brute-Force matcher takes the descriptor of one feature in first set and is \n",
    "#matched with all other features in second set using some distance calculation.\n",
    "# create Matcher object\n",
    "\n",
    "matcher = cv2.DescriptorMatcher_create(cv2.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING)\n",
    "\n",
    "# Match descriptors.\n",
    "matches = matcher.match(des1, des2, None)  #Creates a list of all matches, just like keypoints\n",
    "\n",
    "# Sort them in the order of their distance.\n",
    "matches = sorted(matches, key = lambda x:x.distance)\n",
    "\n",
    "#Like we used cv2.drawKeypoints() to draw keypoints, \n",
    "#cv2.drawMatches() helps us to draw the matches. \n",
    "#https://docs.opencv.org/3.0-beta/modules/features2d/doc/drawing_function_of_keypoints_and_matches.html\n",
    "# Draw first 10 matches.\n",
    "img3 = cv2.drawMatches(im1,kp1, im2, kp2, matches[:10], None)\n",
    "\n",
    "cv2.imshow(\"Matches image\", img3)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#Now let us use these key points to register two images. \n",
    "#Can be used for distortion correction or alignment\n",
    "#For this task we will use homography. \n",
    "# https://docs.opencv.org/3.4.1/d9/dab/tutorial_homography.html\n",
    "\n",
    "# Extract location of good matches.\n",
    "# For this we will use RANSAC.\n",
    "#RANSAC is abbreviation of RANdom SAmple Consensus, \n",
    "#in summary it can be considered as outlier rejection method for keypoints.\n",
    "#http://eric-yuan.me/ransac/\n",
    "#RANSAC needs all key points indexed, first set indexed to queryIdx\n",
    "#Second set to #trainIdx. \n",
    "\n",
    "points1 = np.zeros((len(matches), 2), dtype=np.float32)  #Prints empty array of size equal to (matches, 2)\n",
    "points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "\n",
    "for i, match in enumerate(matches):\n",
    "   points1[i, :] = kp1[match.queryIdx].pt    #gives index of the descriptor in the list of query descriptors\n",
    "   points2[i, :] = kp2[match.trainIdx].pt    #gives index of the descriptor in the list of train descriptors\n",
    "\n",
    "#Now we have all good keypoints so we are ready for homography.   \n",
    "# Find homography\n",
    "#https://en.wikipedia.org/wiki/Homography_(computer_vision)\n",
    "  \n",
    "h, mask = cv2.findHomography(points1, points2, cv2.RANSAC)\n",
    " \n",
    "  # Use homography\n",
    "height, width, channels = im2.shape\n",
    "im1Reg = cv2.warpPerspective(im1, h, (width, height))  #Applies a perspective transformation to an image.\n",
    "   \n",
    "print(\"Estimated homography : \\n\",  h)\n",
    "\n",
    "cv2.imshow(\"Registered image\", im1Reg)\n",
    "cv2.waitKey()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
